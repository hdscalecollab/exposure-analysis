{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Total] Exposure Analysis with Kernel Density Estimation (KDE)\n",
    "\n",
    "////////////////////////////////////////////////////////////////////////////////////\n",
    "##### Author: Jay (Jiue-An) Yang\n",
    "##### Organization: Health Data at Scale Collaboratory, City of Hope\n",
    "##### Version: 3.0\n",
    "##### Last Updated: June 04, 2021\n",
    "////////////////////////////////////////////////////////////////////////////////////\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements:\n",
    "##### 1. ArcGIS Pro 2.7+\n",
    "##### 2. A file directory with .csv files containing GPS points\n",
    "##### 3. A file directory with raster files of env variables that needs to be processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Model Workflow as in ArcGIS Model Builder\n",
    "\n",
    "![Alt text](KDE_Analysis_csv_08072020.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# < Main script starts here >\n",
    "\n",
    "### Step 1: Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.sa import *\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "import glob\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set parameters for model execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:43:15.796408Z",
     "iopub.status.busy": "2021-01-10T23:43:15.795413Z",
     "iopub.status.idle": "2021-01-10T23:43:15.827326Z",
     "shell.execute_reply": "2021-01-10T23:43:15.826329Z",
     "shell.execute_reply.started": "2021-01-10T23:43:15.796408Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set environment options\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# Set methods and Point type\n",
    "running_method = 'KDE'              ## Set the methods that you are running (KDE/DR/SJ)\n",
    "point_type = 'Walking'              ## Set the methods that you are running (AllPoint/Stationary/Vehicle/Walking)\n",
    "\n",
    "# Set environment variables\n",
    "env.workspace = r\"//full-path-to-your-workspace.gdb//\"        ## full path to your ArcGIS workspace geodatabase (.gdb)\n",
    "project_dir =   r\"//full-path-to-your-project-folder//\"       ## full path to your project folder (a directory)\n",
    "gps_data_dir =  r\"//full-path-to-your-GPS-dataset-folder//\"   ## full path to your gps data set (a directory that contains .csv for each participant)\n",
    "\n",
    "x_cord_name = 'lng'                  ## column name for x coordinates in point csv \n",
    "y_cord_name = 'lat'                  ## column name for y coordinates in point csv \n",
    "final_output_table = env.workspace + \"/final_output_table_KDE_Walking\"   ## define a name of the desired output table (in the workspace geodatabase)\n",
    "final_output_table_output_dir = r\"//full-path-to-output-folder//\"  ## full path to your project output folder (a directory), can be same as the project_dir\n",
    "\n",
    "# set KDE parameters\n",
    "kde_cell_size = 10\n",
    "kde_search_radius = 200\n",
    "\n",
    "# Set path to some specific layers\n",
    "research_area = r\"//full-path-to-your-research-area-polygon//\"   ## full path to your research area polygon (can be a .shp or a feature class in a geodatabase)\n",
    "exposure_layer = r\"//full-path-to-your-exposure-raster-layer//\"  ## full path to your exposure raster layer (can be a standalone or a raster in a geodatabase)\n",
    "exposure_layer_name = \"Name-of-your-exposure\"   ## define a name for this exposure layer, this is for the output table \n",
    "\n",
    "# Specify spatial reference for the analysis\n",
    "spatial_ref = arcpy.SpatialReference('North America Albers Equal Area Conic')   ## define the projection that will be used for analysis\n",
    "\n",
    "# Just a lazy way of getting the ID section from your .csv filenames \n",
    "# ex. filename is \"SD000123.csv\", so the range if ID is [-12:-4] from the filename --> 'SD000123'\n",
    "pt_ID_start = -12\n",
    "pt_ID_end  = -4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define additional functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:43:17.664087Z",
     "iopub.status.busy": "2021-01-10T23:43:17.664087Z",
     "iopub.status.idle": "2021-01-10T23:43:17.674060Z",
     "shell.execute_reply": "2021-01-10T23:43:17.673063Z",
     "shell.execute_reply.started": "2021-01-10T23:43:17.664087Z"
    }
   },
   "outputs": [],
   "source": [
    "### Function to normalize the KDE raster to a defined scale\n",
    "\n",
    "def normalize_raster(in_raster):\n",
    "\n",
    "    # Load data, convert to numpy array\n",
    "    array = arcpy.RasterToNumPyArray(in_raster)\n",
    "    \n",
    "    # Defined the scale for normalization\n",
    "    # scale = 1    for the scale of 0-1\n",
    "    # scale = 100  for the scale of 0-100\n",
    "    scale = 1  \n",
    "    \n",
    "    # Normalize cells to 0-1\n",
    "    new_array = (array - array.min()) / (array.max() - array.min()) * scale\n",
    "\n",
    "    # Convert back to a raster\n",
    "    new_raster = arcpy.NumPyArrayToRaster(\n",
    "        in_array=new_array,\n",
    "        lower_left_corner=in_raster.extent.lowerLeft,\n",
    "        x_cell_size=in_raster.meanCellWidth,\n",
    "        y_cell_size=in_raster.meanCellHeight,\n",
    "    )\n",
    "    \n",
    "    return new_raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Model execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T23:43:19.363802Z",
     "iopub.status.busy": "2021-01-10T23:43:19.363802Z",
     "iopub.status.idle": "2021-01-10T23:43:50.728926Z",
     "shell.execute_reply": "2021-01-10T23:43:50.726930Z",
     "shell.execute_reply.started": "2021-01-10T23:43:19.363802Z"
    }
   },
   "outputs": [],
   "source": [
    "### Clear final output table if there is data inside\n",
    "if int(arcpy.GetCount_management(\"final_output_table\")[0]) > 0:\n",
    "    arcpy.DeleteRows_management(\"final_output_table\")\n",
    "\n",
    "\n",
    "### Create a log file\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "log_file_name = \"log_\" + dt_string + \".txt\"\n",
    "f = open(final_output_table_output_dir + log_file_name, \"a\")\n",
    "\n",
    "\n",
    "### Placeholders \n",
    "processed_pts = 0\n",
    "non_processed_pts = []  ## list to store non-processed PTs\n",
    "    \n",
    "    \n",
    "### Loop through .csv files in the data directory\n",
    "i = 1\n",
    "total_i = len(glob.glob(gps_data_dir + \"*.csv\"))\n",
    "\n",
    "for file in glob.glob(gps_data_dir + \"*.csv\"):\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    # check if file is .csv\n",
    "    if file[-4:] == '.csv':\n",
    "        \n",
    "        pt_ID = file[pt_ID_start:pt_ID_end]\n",
    "        msg = \"Working on : {pt} ({index}/{total})\".format(pt = pt_ID, index = i, total= total_i)\n",
    "        print (msg)\n",
    "        \n",
    "        \n",
    "        ### make sure there are points in the .csv\n",
    "        df = pd.read_csv(file)\n",
    "        if len(df) > 10:        \n",
    "            ### --------------------------------------------------------\n",
    "            ### Step 1: Create feature class from CSV points\n",
    "            ### --------------------------------------------------------\n",
    "\n",
    "            arcpy.management.XYTableToPoint(file, \"point_fc\", x_cord_name, y_cord_name, \"\", arcpy.SpatialReference(4326))\n",
    "            print (\"Step 1: csv converted to feature class\")\n",
    "\n",
    "            ### --------------------------------------------------------\n",
    "            ### Step 2: Re-project feature class\n",
    "            ### --------------------------------------------------------\n",
    "\n",
    "            arcpy.Project_management(\"point_fc\", \"point_fc_proj\", spatial_ref)\n",
    "            print (\"Step 2: feature class re-projected to - \", spatial_ref.name)\n",
    "\n",
    "            ### --------------------------------------------------------\n",
    "            ### Step 3: Clip feature class by analysis extent\n",
    "            ### --------------------------------------------------------\n",
    "\n",
    "            arcpy.Clip_analysis(\"point_fc_proj\", research_area, \"point_fc_cliped\")\n",
    "            print (\"Step 3: feature class clipped by research area\")\n",
    "\n",
    "            ### --------------------------------------------------------\n",
    "            ### Step 4: Create KDE \n",
    "            ### --------------------------------------------------------\n",
    "\n",
    "            KDE_raster = KernelDensity(in_features=\"point_fc_cliped\",population_field='NONE', cell_size=kde_cell_size, search_radius=kde_search_radius, area_unit_scale_factor=\"SQUARE_MAP_UNITS\", method=\"PLANAR\")\n",
    "            KDE_raster.save(\"KDE_output\")\n",
    "            print (\"Step 4: KDE raster created\")\n",
    "\n",
    "            ### --------------------------------------------------------\n",
    "            ### Step 5: Normalize the Raster to 0-1\n",
    "            ### --------------------------------------------------------\n",
    "\n",
    "            KDE_raster_normalized = normalize_raster(KDE_raster)\n",
    "            arcpy.DefineProjection_management(KDE_raster_normalized, spatial_ref)\n",
    "            KDE_raster_normalized.save(env.workspace + \"/KDE_output_NM\")\n",
    "            print (\"Step 5: KDE raster normalized to 0-1 scale\")\n",
    "\n",
    "            ### --------------------------------------------------------        \n",
    "            ### Step 6: Set small values to Null\n",
    "            ### --------------------------------------------------------\n",
    "\n",
    "            KDE_raster_normalized_Nullfor0 = SetNull(env.workspace + \"/KDE_output_NM\", env.workspace + \"/KDE_output_NM\", \"VALUE < 0.00001\")\n",
    "            KDE_raster_normalized_Nullfor0.save(env.workspace + \"/KDE_output_NM_Null\")\n",
    "            print (\"Step 6: Tiny values in the KDE raster set to Null\")\n",
    "\n",
    "            ### --------------------------------------------------------\n",
    "            ### Step 7: Calculate Exposrue of the KDE\n",
    "            ### --------------------------------------------------------\n",
    "\n",
    "            weighted_exposure = Raster(KDE_raster_normalized_Nullfor0) * Raster(exposure_layer)\n",
    "            weighted_exposure.save(env.workspace + \"/Weighted_Exposure\") \n",
    "            print (\"Step 7: Weight exposure computed\")\n",
    "\n",
    "            ### --------------------------------------------------------\n",
    "            ### Step 8: Calculate statistics for the participant\n",
    "            ### --------------------------------------------------------\n",
    "\n",
    "            exposure_statistics_table = ZonalStatisticsAsTable(research_area, \"OBJECTID\", weighted_exposure, env.workspace + \"/exposure_table\", \"DATA\", \"ALL\")\n",
    "            print (\"Step 8: Exposure statistics computed\")\n",
    "            \n",
    "            ### --------------------------------------------------------\n",
    "            ### Step 9: Add an new identifiet field to the table\n",
    "            ### Step 10: Add PT_ID to this field\n",
    "            ### --------------------------------------------------------\n",
    "\n",
    "            arcpy.AddField_management(\"exposure_table\", \"PT_ID\", \"TEXT\", \"\",\"\", 100, \"\", \"NULLABLE\", \"\",\"\")\n",
    "            print (\"Step 9: 'PT_ID field' added to output table\")\n",
    "\n",
    "            arcpy.CalculateField_management(\"exposure_table\", \"PT_ID\", \"pt_ID\", \"PYTHON3\")    \n",
    "            print (\"Step 10: ID of [\", pt_ID, \"] added to output table\")\n",
    "\n",
    "            ### --------------------------------------------------------\n",
    "            ### Step 11: Append the participant results table to the final output table\n",
    "            ### --------------------------------------------------------\n",
    "\n",
    "            arcpy.Append_management(\"exposure_table\", \"final_output_table\")\n",
    "            print (\"Step 11: Exposure results for [\", pt_ID, \"] added to output table\")\n",
    "            \n",
    "            processed_pts += 1\n",
    "    \n",
    "        else:  ### Write to log file to record this pt without points\n",
    "            non_processed_pts.append(pt_ID)\n",
    "            f.write(\"Participant ID: {} was not processed.\\n\".format(pt_ID))                    \n",
    "\n",
    "        i+=1           \n",
    "\n",
    "        \n",
    "### --------------------------------------------------------\n",
    "### Step 12: Convert Table to Pandas Dataframe\n",
    "### --------------------------------------------------------\n",
    "\n",
    "if processed_pts > 0:\n",
    "\n",
    "    field_names = [f.name for f in arcpy.ListFields(\"final_output_table\")]\n",
    "    np_arr = arcpy.da.TableToNumPyArray(\"final_output_table\", field_names)\n",
    "\n",
    "    df = pd.DataFrame(data = np_arr)\n",
    "    df.to_csv(final_output_table_output_dir + \"Exposure_Table_\" + running_method + '_' + point_type + '_' + exposure_layer_name + \".csv\", index = False)\n",
    "\n",
    "    print (\"-\"*30)\n",
    "    print (\"KDE Exposure Analysis Completed !\")\n",
    "    print (\"Output table available at : \", final_output_table_output_dir + \"Exposure_Table_\" + exposure_layer_name + \".csv\")\n",
    "    #Final output table is saved as a .csv file in the defined [final_output_table_output_dir] location.\n",
    "    \n",
    "    ### Close the log file\n",
    "    f.close()\n",
    "    print (\"Please also check the log file for non-processed participants at : {}\".format(log_file_name))\n",
    "    \n",
    "\n",
    "else:     \n",
    "    ### Close the log file\n",
    "    f.write(\"-\"*30)\n",
    "    f.write(\"\\nThere are no exposure resutls for the entire run.\")\n",
    "    f.close()\n",
    "    print (\"-\"*30)\n",
    "    print (\"There are no exposure resutls for the entire run.\")\n",
    "    print (\"Please also check the log file at : {}\".format(log_file_name))       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "python",
   "name": "arcgispro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
